#!/usr/bin/env python3
##############################################################################
#
# Copyright (c) 2022, 2023 Qualcomm Technologies, Inc.
# All Rights Reserved.
# Confidential and Proprietary - Qualcomm Technologies, Inc.
#
# All data and information contained in or disclosed by this document are
# confidential and proprietary information of Qualcomm Technologies, Inc., and
# all rights therein are expressly reserved. By accepting this material, the
# recipient agrees that this material and the information contained therein
# are held in confidence and in trust and will not be used, copied, reproduced
# in whole or in part, nor its contents revealed in any manner to others
# without the express written permission of Qualcomm Technologies, Inc.
#
##############################################################################

import os
import sys
import argparse
import logging
import shutil
import yaml
import csv

if os.path.isdir(os.path.abspath(os.path.join(sys.path[0], '../python/'))):
    sys.path.insert(0, os.path.abspath(os.path.join(sys.path[0], '../python/')))
else:
    sys.path.insert(0, os.path.join(os.environ['QNN_SDK_ROOT'], 'lib', 'python'))

import qti.aisw.accuracy_evaluator.common.defaults as df
from qti.aisw.accuracy_evaluator.qacc import defaults

dev_config_qnn_sdk_dir = None
#Set the environment from the config
if defaults.get_value("developer_config.enabled"):
    environment = defaults.get_env()
    if environment["ONNX_HOME"]:
        ONNX_HOME = environment["ONNX_HOME"]
        sys.path.append(ONNX_HOME)
        sys.path.append(os.path.join(ONNX_HOME, "distribute"))
        sys.path.append(os.path.join(ONNX_HOME, "dependencies/python"))
    if environment["TENSORFLOW_HOME"]:
        TF_HOME= environment["TENSORFLOW_HOME"]
        sys.path.append(TF_HOME)
        sys.path.append(os.path.join(TF_HOME, "distribute"))
        sys.path.append(os.path.join(TF_HOME, "dependencies/python"))
    if environment["QNN_SDK_ROOT"]:
        dev_config_qnn_sdk_dir = environment["QNN_SDK_ROOT"]
else:
    # Removing the local path.
    sys.path.pop(0)

from qti.aisw.accuracy_evaluator.qacc import *
import qti.aisw.accuracy_evaluator.qacc.manager as manager
import qti.aisw.accuracy_evaluator.common.exceptions as ce
import qti.aisw.accuracy_evaluator.qacc.configuration as qc
from qti.aisw.accuracy_evaluator.common.utilities import Helper, ModelType
from qti.aisw.accuracy_evaluator.qacc.utils import check_model_dir, process_model_dir,\
                                                   create_default_config

def prepare_work_dir(work_dir, prompt):
    """
    Deletes temp directory before execution starts
    """
    logging.warning('Directory {} will be deleted if already exists. Take backup before '
                        'execution.'.format(work_dir))
    user_input = input('Do you want to start execution? (yes/no) :').lower() if prompt else 'y'
    if user_input in ['yes', 'y']:
        temp_dir = os.path.join(work_dir)
        if os.path.exists(temp_dir):
            shutil.rmtree(temp_dir)
    else:
        sys.exit(1)
    # create empty temp dir
    os.makedirs(temp_dir)

def main():
    parser = argparse.ArgumentParser(description='qnn-accuracy-evaluator options')
    parser._action_groups.pop()
    min_mode = parser.add_argument_group('minimal mode options')

    min_mode.add_argument('-model',
                          help='path to model or model directory, available only for htp or aic platform')
    min_mode.add_argument('-backend', choices = ['htp', 'aic'],
                          help="Backend to run the inference")
    min_mode.add_argument('-target-arch', choices = ['aarch64-android', 'x86_64-linux-clang'],
                          help='Target architecture to compile.')
    min_mode.add_argument('-comparator', type=str, help='comparator to be used.')
    min_mode.add_argument('-tol-thresh', default=0.01, type=float,
                          help='Tolerance threshold to be used for the comparator')
    min_mode.add_argument('-act-bw', type=str, help='[Optional] bitwidth to use for activations.'
                                                    ' E.g., 8, 16. Default is 8.')
    min_mode.add_argument('-bias-bw', type=str, help='[Optional] bitwidth to use for biases. '
                                                    ' either 8 (default) or 32.')
    min_mode.add_argument('-box-input', type=str, help='Path to the json file. Used only '
                                                       ' with the box comparator')

    config_mode = parser.add_argument_group('config mode options')
    config_mode.add_argument('-config', help='path to model config yaml')

    pipeoptions = parser.add_argument_group('pipeline options')
    pipeoptions.add_argument('-preproc-file',
                             help='preprocessed input file, overrides inputfile provided in model config')
    pipeoptions.add_argument('-calib-file',
                             help='calibration input file, overrides calibration file provided in model config')

    otheroptions = parser.add_argument_group('other options')
    otheroptions.add_argument('-input-info', nargs=2, action='append',
                              help="The name and dimension of all the input buffers to the network specified in\n"
                              "the format [input_name comma-separated-dimensions],\n"
                              "for example: 'data' 1,224,224,3. \n"
                               "This option is mandatory for pytorch models in minimal mode.")
    otheroptions.add_argument('-device-id',
                              help='Target device id to be provided')
    otheroptions.add_argument('-work-dir', default='qacc_temp', help='working directory path.'
                                                                     ' default is ./qacc_temp')
    otheroptions.add_argument('-cleanup', choices=['end', 'intermediate'],
                              default='', help='cleanup preprocessing, inference and postprocessing'
                                               ' output files. -cleanup end: deletes the files after'
                                               ' all stages are completed. -cleanup intermediate: '
                                               'deletes the intermediate inference and postprocessing'
                                               ' output files. Selecting intermediate option saves '
                                               'space but disables comparator option')
    otheroptions.add_argument('-silent', action='store_true',
                              help='Run in silent mode. default enabled in minimal mode')
    otheroptions.add_argument('-platform', help='run only on this platform')
    otheroptions.add_argument('-platform-tag', help='run only this platform tag')

    otheroptions.add_argument('-batchsize', help='overrides batchsize provided in model config')
    otheroptions.add_argument('-platform-tag-params',
                              help='Update platform params based on platform-tag supplied in '
                                   'config', action='append', nargs='+')
    otheroptions.add_argument('-onnx-symbol', action='append', nargs='+',
                              help='Replace onnx symbols in input/output shapes.' +
                                   'Can be passed multiple times' +
                                   'Default replaced by 1. e.g __unk_200:1')
    otheroptions.add_argument('-set-global', action='append', nargs='+',
                              help='Replace global symbols with given value.' +
                                   'Can be passed multiple times. ' +
                                   'e.g <symbol>:2')

    args = parser.parse_args()
    args.inference_strategy = 'distributed'
    args.enable_perf = False
    args.perf_iter_count = 200
    args.infer_file = None

    #Get the qnn-sdk-dir from env
    qnn_sdk_dir = os.environ['QNN_SDK_ROOT']
    if not qnn_sdk_dir and dev_config_qnn_sdk_dir is None:
        logging.error("QNN_SDK_ROOT variable is not set.")
        sys.exit(1)
    elif dev_config_qnn_sdk_dir is not None:
        args.qnn_sdk_dir = dev_config_qnn_sdk_dir
    else:
        args.qnn_sdk_dir = qnn_sdk_dir

    prepare_work_dir(args.work_dir, not args.silent)

    defaults = df.Defaults.getInstance()
    defaults.set_log(args.work_dir + '/qacc.log')
    qaic_logger.info('===========================================================')
    qaic_logger.info('QAIC Accuracy Evaluator (qacc)')

    #Check for config mode or minimal mode.
    if not (args.config or (args.model and args.backend and args.target_arch)):
        logging.error("Please provide config file or params for minimal mode")
        sys.exit(1)

    #Minimal Mode - Create the config file if cli options have been passed.
    #Minimal mode overrides the config mode if both options are given.
    if args.model:
        args.config = create_default_config(args.work_dir, args.model,
                                            args.backend, args.target_arch,
                                            args.comparator, args.tol_thresh,
                                            args.input_info, args.act_bw,
                                            args.bias_bw, args.box_input)
        args.silent = True #Make it default in minimal mode.

    #Check if model path or directory path is given.
    is_model_dir, model_path = check_model_dir(args.config)
    if is_model_dir:
        models, preproc_files, work_dirs = process_model_dir(model_path, args.work_dir)

    if not is_model_dir:
        try:
            mgr = manager.QACCManager(config_path=args.config, work_dir=args.work_dir,
                                  set_global=args.set_global, batchsize=args.batchsize)
            status = mgr.run_pipeline(platform_name=args.platform, work_dir=args.work_dir,
                                  platform_tag=args.platform_tag, cleanup=args.cleanup,
                                  onnx_symbol=args.onnx_symbol, device_id=args.device_id,
                                  platform_tag_params=args.platform_tag_params,
                                  inference_strategy=args.inference_strategy, silent=args.silent,
                                  cli_preproc_file=args.preproc_file,
                                  cli_infer_file=args.infer_file, enable_perf_flag=args.enable_perf,
                                  perf_iter_count=args.perf_iter_count,
                                  qnn_sdk_dir=args.qnn_sdk_dir, backend=args.backend)
        except Exception as e:
            logging.error('qacc failed to run the pipeline. See log for more details')
            qaic_logger.exception(e)
            sys.exit(1)
        if status:
            logging.error('qacc failed to run the pipeline. See log for more details')
            sys.exit(1)
        else:
            logging.info('qacc pipeline ended successfully')

    else:
        logging.info("Running in Model directory mode")
        logging.info(f"Total no of models : {len(models)}")
        model_status = {}
        for model, preproc_file, work_dir in zip(models, preproc_files, work_dirs):
            try:
                logging.info(f"Running the Accuracy Evaluator for model - {model}")
                mgr = manager.QACCManager(config_path=args.config, work_dir=work_dir,
                                  set_global=args.set_global, batchsize=args.batchsize, model_path=model)
                status = mgr.run_pipeline(platform_name=args.platform, work_dir=work_dir,
                                  platform_tag=args.platform_tag, cleanup=args.cleanup,
                                  onnx_symbol=args.onnx_symbol, device_id=args.device_id,
                                  platform_tag_params=args.platform_tag_params,
                                  inference_strategy=args.inference_strategy, silent=args.silent,
                                  cli_preproc_file=preproc_file,
                                  cli_infer_file=args.infer_file, enable_perf_flag=args.enable_perf,
                                  perf_iter_count=args.perf_iter_count,
                                  qnn_sdk_dir=args.qnn_sdk_dir, backend=args.backend)
            except:
                model_status[model] = "FAIL"
                continue

            if status:
                model_status[model] = "FAIL"
            else:
                model_status[model] = "PASS"

        dump_model_status(model_status)

def dump_model_status(model_status):
    """
    Dump the model status to a csv file
    """
    failed_count = [i for i in model_status.values() if i =="FAIL"]
    logging.info(f"Total models failed: {len(failed_count)}")
    with open("model_status.csv", 'w') as csv_file:
        csv_writer = csv.writer(csv_file)
        for key, value in model_status.items():
            csv_writer.writerow([key, value])

if __name__ == "__main__":
    main()
