#!/usr/bin/env python3
# -*- mode: python -*-
# ==============================================================================
#
#  Copyright (c) 2020-2023 Qualcomm Technologies, Inc.
#  All Rights Reserved.
#  Confidential and Proprietary - Qualcomm Technologies, Inc.
# ==============================================================================
import sys
import traceback

from qti.aisw.converters import onnx as onnx_frontend
from qti.aisw.converters.common.utils.converter_utils import log_error
from qti.aisw.converters.common.utils.argparser_util import ArgParserWrapper, CustomHelpFormatter
from qti.aisw.converters.common.converter_ir.op_graph_optimizations import IROptimizations
from qti.aisw.converters.common.arch_linter.arch_linter import ArchLinter
from qti.aisw.converters.backend.ir_to_qnn import QnnConverterBackend
from qti.aisw.converters.backend.qnn_quantizer import QnnQuantizer
from qti.aisw.converters.backend.custom_ops.op_factory import QnnCustomOpFactory


class ONNXtoQNNArgParser(ArgParserWrapper):
    def __init__(self):
        super(ONNXtoQNNArgParser, self).__init__(formatter_class=CustomHelpFormatter,
                                                 conflict_handler='resolve',
                                                 parents=[onnx_frontend.OnnxConverterFrontend.ArgParser(),
                                                          IROptimizations.ArgParser(),
                                                          QnnQuantizer.ArgParser(),
                                                          QnnConverterBackend.ArgParser(),
                                                          ArchLinter.ArgParser()
                                                          ])
        self.parser.description = 'Script to convert ONNX model into QNN'


def main():
    parser = ONNXtoQNNArgParser()
    args = parser.parse_args()

    try:
        converter = onnx_frontend.OnnxConverterFrontend(args, custom_op_factory = QnnCustomOpFactory())
        ir_graph = converter.convert()

        # Override optimizer flags for QNN backend
        args.perform_axes_to_spatial_first_order = True
        args.squash_box_decoder = True
        args.match_caffe_ssd_to_tf = True
        args.adjust_nms_features_dims = True
        args.extract_color_transform = True
        args.preprocess_roi_pool_inputs = True
        args.unroll_lstm_time_steps= True
        args.expand_gru_op_structure = True
        args.unroll_gru_time_steps = True
        args.inject_cast_for_gather = True
        args.force_prune_cast_ops = False
        args.align_matmul_ranks = True
        args.handle_gather_negative_indices = True

        optimizer = IROptimizations(args)
        optimized_graph = optimizer.optimize(ir_graph)

        backend = QnnConverterBackend(args)
        backend.save(optimized_graph)

        archLinter = ArchLinter(args)
        archLinter.run_linter(optimized_graph, backend)
    except Exception as e:
        log_error("Encountered Error: {}".format(str(e)))
        traceback.print_exc()
        sys.exit(1)


if __name__ == '__main__':
    main()
