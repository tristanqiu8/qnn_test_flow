#!/usr/bin/env python3
#=============================================================================
#
#  Copyright (c) 2021-2023 Qualcomm Technologies, Inc.
#  All Rights Reserved.
#  Confidential and Proprietary - Qualcomm Technologies, Inc.
#
#=============================================================================
import os
import sys

sys.path.insert(0, os.path.abspath(os.path.join(sys.path[0], os.path.join('../..', 'lib', 'python'))))
import re
import json
import tarfile
from collections import OrderedDict
import json
import numpy as np
from pathlib import Path
import re
import signal
import tarfile
from typing import NoReturn

import qti.aisw.quantization_checker.utils.Constants as Constants
from qti.aisw.quantization_checker.QOptionGenerator import QOptionGenerator
from qti.aisw.quantization_checker.QOptionRunner import QOptionRunner
from qti.aisw.quantization_checker.utils import utils
from qti.aisw.quantization_checker.utils.ConfigParser import *
from qti.aisw.quantization_checker.utils.DataFormatter import DataFormatter
from qti.aisw.quantization_checker.utils.HistogramVisualizer import (
    HistogramGeneration, visualizeBiasTensors,
    visualizePerChannelWeightTensors, visualizeWeightTensors)
from qti.aisw.quantization_checker.utils.Logger import PrintOptions, getLogger
from qti.aisw.quantization_checker.utils.Op import Op
from qti.aisw.quantization_checker.utils.Processor import Processor
from qti.aisw.quantization_checker.utils.Progress import (Progress,
                                                          ProgressStage)
def interruptHandler(signum, frame) -> NoReturn:
    print('Exit requested by user, program will now exit...')
    sys.exit(0)

signal.signal(signal.SIGINT, interruptHandler)

def main() -> NoReturn:
    args = utils.getArguments()
    model = None
    inputList = None
    sdkDir = None
    activationWidth = None
    biasWidth = None
    weightWidth = None
    outputDir = None
    generateHist = HistogramGeneration.SKIP_GENERATION
    outputCsv = None
    quantOverridesPath = None
    quantizationOptions = None
    quantizationAlgorithms = None

    configParams = extractConfigParams(args.config_file)
    comparisonAlgorithms = setDefaultAlgorithms()

    if configParams is not None:
        if "model" in configParams:
            model = configParams["model"]
        if "input_list" in configParams:
            inputList = configParams["input_list"]
        if "activation_width" in configParams:
            activationWidth = configParams["activation_width"]
        if "bias_width" in configParams:
            biasWidth = configParams["bias_width"]
        if "weight_width" in configParams:
            weightWidth = configParams["weight_width"]
        if "output_dir" in configParams:
            outputDir = configParams["output_dir"]
        if "weight_comparison_algorithms" in configParams:
            comparisonAlgorithms["weight_comparison_algorithms"] = configParams["weight_comparison_algorithms"]
        if "bias_comparison_algorithms" in configParams:
            comparisonAlgorithms["bias_comparison_algorithms"] = configParams["bias_comparison_algorithms"]
        if "act_comparison_algorithms" in configParams:
            comparisonAlgorithms["act_comparison_algorithms"] = configParams["act_comparison_algorithms"]
        if "input_data_analysis_algorithms" in configParams:
            comparisonAlgorithms["input_data_analysis_algorithms"] = configParams["input_data_analysis_algorithms"]
        if "input_dimension" in configParams:
            inputDimension = configParams["input_dimension"]
        if "output_csv" in configParams:
            outputCsv = configParams["output_csv"]
        if "generate_histogram" in configParams and configParams["generate_histogram"] == True:
            generateHist = HistogramGeneration.GENERATE_HISTOGRAM
        if "per_channel_histogram" in configParams and configParams["per_channel_histogram"] == True:
            generateHist = HistogramGeneration.GENERATE_PER_CHANNEL_HISTOGRAM
        if "quantization_overrides" in configParams and os.path.exists(configParams["quantization_overrides"]) == True:
            quantOverridesPath = configParams["quantization_overrides"]
        if "quantization_variations" in configParams:
            quantizationOptions = configParams['quantization_variations']
            if quantizationOptions and quantizationOptions[0] != Constants.UNQUANTIZED:
                quantizationOptions.insert(0, Constants.UNQUANTIZED)
        if "quantization_algorithms" in configParams:
            quantizationAlgorithms = configParams["quantization_algorithms"]

    if args.model:
        model = args.model
    if args.input_list:
        inputList = args.input_list
    if args.activation_width:
        activationWidth = args.activation_width
    if args.bias_width:
        biasWidth = args.bias_width
    if args.weight_width:
        weightWidth = args.weight_width
    if args.output_dir:
        outputDir = args.output_dir
    if args.generate_histogram:
        generateHist = HistogramGeneration.GENERATE_HISTOGRAM
    if args.per_channel_histogram:
        generateHist = HistogramGeneration.GENERATE_PER_CHANNEL_HISTOGRAM
    if args.output_csv:
        outputCsv = args.output_csv
    skipBuild = args.skip_building_model
    skipGenerator = args.skip_generator
    skipRunner = args.skip_runner
    sdkDir = retrieveQnnSdkDir(os.path.abspath(__file__))
    if activationWidth is not None:
        Op.setActivationWidth(activationWidth)
    if biasWidth is not None:
        Op.setBiasWidth(biasWidth)
    if not quantizationOptions:
        quantizationOptions = [
                                    'unquantized',
                                    'enhanced',
                                    'tf',
                                    'adjusted',
                                    'symmetric',
                                 ]
    if not quantizationAlgorithms:
        quantizationAlgorithms = ['cle', 'pcq']
    if outputDir is None:
        print("ERROR! Output directory has not been specified, tool will now exit...")
        exit(-1)
    if model is None:
        print("ERROR! Input model file or directory of models has not been specified, tool will now exit...")
        exit(-1)

    logger = getLogger(outputDir, model, "qnn-quantization-checker-log")

    if sdkDir is None or not os.path.exists(sdkDir):
        logger.print("ERROR! Path to QNN SDK doesn't exist, please check the file path!")
        exit(-1)

    Progress.setProgressInfo(model, logger, skipGenerator, skipBuild, skipRunner)
    result = 0
    if os.path.isdir(model):
        models = utils.buildModelDict(model)
        skipFirstModel = True
        for modelData in models.values():
            if not skipFirstModel:
                Progress.updateModelProgress()
            skipFirstModel = False
            Progress.updateProgressLimit()
            outputDir = os.path.dirname(modelData['modelFile'])
            if not os.path.exists(outputDir):
                os.makedirs(outputDir)
            inputFileNames = getInputFiles(modelData['inputList'])
            result = doAnalysis(
                        quantizationOptions, quantizationAlgorithms, modelData['modelFile'], logger, modelData['inputList'], sdkDir,
                        activationWidth, biasWidth, weightWidth, outputDir, skipBuild, skipGenerator, skipRunner,
                        inputFileNames, comparisonAlgorithms, args.config_file, generateHist, outputCsv, quantOverridesPath
                    )
        Progress.updateProgress(Progress.getRemainingProgress())
        Progress.finishProcessor()
        exit(result)
    elif os.path.isfile(model):
        Progress.updateProgressLimit()
        if inputList is None or not os.path.exists(inputList):
            logger.print("ERROR! List of input files doesn't exist, please check the file path!")
            exit(-1)
        inputFileNames = getInputFiles(inputList)
        result = doAnalysis(
                    quantizationOptions, quantizationAlgorithms, model, logger, inputList, sdkDir, activationWidth, biasWidth,
                    weightWidth, outputDir, skipBuild, skipGenerator, skipRunner, inputFileNames, comparisonAlgorithms,
                    args.config_file, generateHist, outputCsv, quantOverridesPath
                )

        Progress.updateProgress(Progress.getRemainingProgress())
        Progress.finishProcessor()
        exit(result)
    else:
        logger.print("ERROR! Incorrect or non-existent model path, please verify the path to the model file is correct!")
        exit(-1)

def doAnalysis(
        quantizationOptions, quantizationAlgorithms, model, logger, inputList, sdkDir, activationWidth, biasWidth, weightWidth, outputDir,
        skipBuild, skipGenerator, skipRunner, inputFileNames, comparisonAlgorithms, userDefinedArgs, generateHist, outputCsv,
        quantOverridesPath
    ):
    result = 0
    quantizationVariations = utils.mergeQuantOptionsAndAlgorithms(quantizationOptions, quantizationAlgorithms)
    quantizationVariationsWithCommand = dict.fromkeys(quantizationVariations, 'Re-quantization skipped.')
    if not skipGenerator:
        result, quantizationVariationsWithCommand = runGenerator(
                    quantizationOptions, quantizationAlgorithms,
                    model, inputList, sdkDir, activationWidth, biasWidth, weightWidth, outputDir,
                    logger, userDefinedArgs, quantOverridesPath
                )
    if result != -1:
        allOps = getAllOpsFromJson(outputDir, quantizationVariations)
        logger.print('Extracting weights and biases files from bin.')
        extractWeightsAndBiasesFiles(quantizationVariations, outputDir)
        logger.print('Extracting weights values from raw files.')
        extractWeights(quantizationVariations, outputDir, allOps, logger)
        logger.print('Extracting biases values from raw files.')
        extractBiases(quantizationVariations, outputDir, allOps, biasWidth)

        processor = Processor(quantizationVariations, comparisonAlgorithms, logger)
        formatter = DataFormatter(outputDir, model, inputFileNames, quantizationVariationsWithCommand, logger)
        formatter.setInputResults(processor.processInputData(extractInputData(inputList, model, logger)))
        if not skipRunner:
            logger.print('Building and running model.')
            result = runRunner(model, inputList, sdkDir, outputDir, skipBuild, logger, userDefinedArgs)
        if result != -1:
            logger.print('Extracting activations from raw files.')
            extractActivations(quantizationVariations, outputDir, allOps, inputFileNames)
            formatter.setActivationsResults(processor.processActivationResults(allOps))

        formatter.setWeightResults(processor.processWeightResults(allOps))
        formatter.setBiasResults(processor.processBiasResults(allOps))
        logger.print('Printing results to log file.')
        formatter.printLog()
        logger.print('Printing results to console file.')
        formatter.printConsole()
        logger.print('Printing results to HTML files.')
        formatter.printHtml()
        if outputCsv:
            logger.print('Printing results to CSV files.')
            formatter.printCsv()

        weightsHistAnalysisDir = os.path.join(outputDir, 'hist_analysis_weights')
        if generateHist == HistogramGeneration.GENERATE_PER_CHANNEL_HISTOGRAM:
            weightsHistAnalysisDir = os.path.join(outputDir, 'hist_analysis_weights')
            visualizePerChannelWeightTensors(quantizationVariations, allOps, weightsHistAnalysisDir, logger)
            biasesHistAnalysisDir = os.path.join(outputDir, 'hist_analysis_biases')
            visualizeBiasTensors(quantizationVariations, allOps, biasesHistAnalysisDir, logger)
        elif generateHist == HistogramGeneration.GENERATE_HISTOGRAM:
            weightsHistAnalysisDir = os.path.join(outputDir, 'hist_analysis_weights')
            visualizeWeightTensors(quantizationVariations, allOps, weightsHistAnalysisDir, logger)
            biasesHistAnalysisDir = os.path.join(outputDir, 'hist_analysis_biases')
            visualizeBiasTensors(quantizationVariations, allOps, biasesHistAnalysisDir, logger)

    return result

def retrieveQnnSdkDir(filePath):
    return str(Path(filePath).parent.parent.parent)

def setDefaultAlgorithms():
    comparisonAlgorithms = {}
    comparisonAlgorithms["input_data_analysis_algorithms"] = [{"algo_name":"stats", "threshold":"2"}]
    comparisonAlgorithms["weight_comparison_algorithms"] = [{"algo_name":"minmax", "threshold":"10"}, {"algo_name":"maxdiff", "threshold":"10"}, {"algo_name":"sqnr", "threshold":"26"}, {"algo_name":"stats", "threshold":"2"}, {"algo_name":"data_range_analyzer"}, {"algo_name":"data_distribution_analyzer", "threshold":"0.6"}]
    comparisonAlgorithms["bias_comparison_algorithms"] = [{"algo_name":"minmax", "threshold":"10"}, {"algo_name":"maxdiff", "threshold":"10"}, {"algo_name":"sqnr", "threshold":"26"}, {"algo_name":"stats", "threshold":"2"}, {"algo_name":"data_range_analyzer"}, {"algo_name":"data_distribution_analyzer", "threshold":"0.6"}]
    comparisonAlgorithms["act_comparison_algorithms"] = [{"algo_name":"minmax", "threshold":"10"}]
    return comparisonAlgorithms

def getInputFiles(inputList):
    with open(inputList) as file:
        inputFileNames = file.readlines()
        inputFileNames = [line.rstrip() for line in inputFileNames]
    return inputFileNames

def getAllOpsFromJson(outputDir, quantizationVariations):
    allOpsMap = {}
    for quantizationVariation in quantizationVariations:
        opsInfo = getOpsFromJsonForQuantizationVariation(outputDir, quantizationVariation)
        if opsInfo is not None:
            allOpsMap[quantizationVariation] = opsInfo
    return allOpsMap

def getOpsFromJsonForQuantizationVariation(outputDir, quantizationVariation):
    jsonFilePath = os.path.join(outputDir, quantizationVariation, quantizationVariation + '_net.json')
    if not os.path.exists(jsonFilePath):
        return
    with open(jsonFilePath) as f:
        modelMeta = json.load(f, object_pairs_hook=OrderedDict)
    return parseOpDataFromJsonMeta(modelMeta)

def parseOpDataFromJsonMeta(modelMeta):
    nodes = modelMeta['graph']['nodes']
    opMap = {}
    for node in nodes.keys():
        op = Op(node)
        activationNodeName = nodes[node]['output_names'][0]
        op.setActivationNodeName(activationNodeName)
        if nodes[node]['input_names']:
            inputNames = nodes[node]['input_names']
            if nodes[node]['type'] == 'LSTM':
                itr = 0
                for inputName in inputNames:
                    if Op.isLSTMBias(itr):
                        op.setBiasName(inputName)
                    else:
                        op.setWeightName(inputName)
                    itr += 1
            elif nodes[node]['type'] in Op.getOpTypesWithWeightsBiases():
                op.setInputNodeName(inputNames[0])
                op.setWeightName(inputNames[1])
                op.setBiasName(inputNames[2])
        opMap[node] = op
    return opMap

def extractActivations(quantizationVariations, outputDir, allOps, inputFileNames):
    for quantizationVariation in quantizationVariations:
        # skip quantized models which are failed to get converted correctly
        if quantizationVariation not in allOps:
            continue
        with open(os.path.join(outputDir, quantizationVariation, quantizationVariation + '_net.json')) as f:
            modelMeta = json.load(f, object_pairs_hook=OrderedDict)
        for item in allOps[quantizationVariation].items():
            op = allOps[quantizationVariation][item[0]]
            activationNodeName = op.getActivationNodeName()
            if activationNodeName is None:
                continue
            if quantizationVariation == Constants.UNQUANTIZED:
                activationPath = os.path.join(outputDir, Constants.NET_RUN_OUTPUT_DIR, Constants.UNQUANTIZED)
                resultCount = 0
                with os.scandir(activationPath) as allResults:
                    activationList = []
                    for resultDir in allResults:
                        if resultDir.is_dir():
                            activationFile = os.path.join(activationPath, resultDir.name, activationNodeName + '.raw')
                            if os.path.exists(activationFile) and os.path.isfile(activationFile):
                                activationList.append((inputFileNames[resultCount], np.fromfile(activationFile, dtype='float32')))
                                resultCount += 1
                    op.setActivations(activationList)
            op.setActivationScale(modelMeta['graph']['tensors'][activationNodeName]['quant_params']['scale_offset']['scale'])
            op.setActivationOffset(modelMeta['graph']['tensors'][activationNodeName]['quant_params']['scale_offset']['offset'])
            if op.getInputNodeName() is not None:
                op.setInputNodeScale(modelMeta['graph']['tensors'][op.getInputNodeName()]['quant_params']['scale_offset']['scale'])
            allOps[quantizationVariation][item[0]] = op

def extractInputData(inputList, model, logger):
    inputData = {}
    try:
        with open(inputList) as file:
            inputDirPath = os.path.dirname(model)
            inputFileNames = file.readlines()
            for line in inputFileNames:
                filenames = line.rstrip()
                for file in filenames.split():
                    if file:
                        file = re.split('=|:', file)[-1]
                        filePath = os.path.join(inputDirPath, file)
                        if not os.path.exists(filePath):
                            logger.print('The following file from the input list (' + filePath + ') could not be found. Exiting...')
                            exit(-1)
                        inputData[file] = np.fromfile(filePath, dtype='float32')
    except Exception as e:
            logger.print("Unable to open input list file, please check the file path! Exiting...")
            logger.print(e, PrintOptions.LOGFILE)
            exit(-1)
    return inputData

def extractWeights(quantizationVariations, outputDir, allOps, logger):
    for quantizationVariation in quantizationVariations:
        # skip quantized models which are failed to get converted correctly
        if quantizationVariation not in allOps:
            continue
        with open(os.path.join(outputDir, quantizationVariation, quantizationVariation + '_net.json')) as f:
            modelMeta = json.load(f, object_pairs_hook=OrderedDict)
        for item in allOps[quantizationVariation].items():
            op = allOps[quantizationVariation][item[0]]
            if op.getWeightName() not in (None, ''):
                weightName = op.getWeightName()
                dtype = None
                quantEncoding = modelMeta['graph']['tensors'][weightName]['quant_params']['encoding']
                op.setIsQuantizedPerChannel(quantEncoding)
                if 'dims' in modelMeta['graph']['tensors'][weightName]:
                    op.setWeightsDims(modelMeta['graph']['tensors'][weightName]['dims'])
                elif 'current_dims' in modelMeta['graph']['tensors'][weightName]:
                    op.setWeightsDims(modelMeta['graph']['tensors'][weightName]['current_dims'])
                else:
                    logger.print('Extracting weight values failed due to keyError while retrieving weight dimension.')
                    exit(-1)
                # quantization encoding=0 for non-pcq weights
                if quantEncoding == 0:
                    op.setWeightsScaleOffset(modelMeta['graph']['tensors'][weightName]['quant_params']['scale_offset'])
                    dtype = 'uint8'
                # quantization encoding=1 for pcq weights
                elif quantEncoding == 1:
                    op.setWeightsScaleOffset(modelMeta['graph']['tensors'][weightName]['quant_params']['axis_scale_offset'])
                    dtype = 'int8'
                if quantizationVariation == Constants.UNQUANTIZED:
                    op.setWeights(np.fromfile(os.path.join(outputDir, quantizationVariation, weightName + '.raw'), dtype='float32'))
                else:
                    op.setWeights(np.fromfile(os.path.join(outputDir, quantizationVariation, weightName + '.raw'), dtype=dtype))
            allOps[quantizationVariation][item[0]] = op

def extractBiases(quantizationVariations, outputDir, allOps, biasWidth):
    for quantizationVariation in quantizationVariations:
        # skip quantized models which are failed to get converted correctly
        if quantizationVariation not in allOps:
            continue
        with open(os.path.join(outputDir, quantizationVariation, quantizationVariation + '_net.json')) as f:
            modelMeta = json.load(f, object_pairs_hook=OrderedDict)
        for item in allOps[quantizationVariation].items():
            op = allOps[quantizationVariation][item[0]]
            if op.getBiasName() not in (None, ''):
                biasName = op.getBiasName()
                op.setBiasScale(modelMeta['graph']['tensors'][biasName]['quant_params']['scale_offset']['scale'])
                op.setBiasOffset(modelMeta['graph']['tensors'][biasName]['quant_params']['scale_offset']['offset'])
                dataType = modelMeta['graph']['tensors'][biasName]['data_type']
                # TODO: check if bias raw file exists and report if not...
                biasRawFilePath = os.path.join(outputDir, quantizationVariation, biasName + '.raw')
                if not os.path.exists(biasRawFilePath):
                    continue
                if quantizationVariation == Constants.UNQUANTIZED:
                    op.setBiases(np.fromfile(biasRawFilePath, dtype='float32'))
                elif dataType == Op.getUint8QnnCode():
                    op.setBiases(np.fromfile(biasRawFilePath, dtype='uint8'))
                else:
                    op.setBiases(np.fromfile(biasRawFilePath, dtype='int32'))
            allOps[quantizationVariation][item[0]] = op

def extractWeightsAndBiasesFiles(quantizationVariations, outputDir):
    for quantizationVariation in quantizationVariations:
        fileToExtract = os.path.join(outputDir, quantizationVariation, quantizationVariation + '.bin')
        if not os.path.exists(fileToExtract):
            continue
        # untar the bin file
        binFile = tarfile.open(fileToExtract, 'r')
        extractDir = os.path.dirname(fileToExtract)
        binFile.extractall(extractDir)

def runRunner(inputNetwork, inputList, sdkDir, outputDir, skipBuild, logger, userDefinedArgs):
    runner = QOptionRunner(Constants.QNN, inputNetwork, inputList, sdkDir, outputDir, userDefinedArgs, logger, skipBuild)
    result = runner.run()
    Progress.updateProgress(Progress.getStepSize(ProgressStage.RUNNER))
    return result

def runGenerator(
        quantizationOptions, quantizationAlgorithms, modelFile, inputList, sdkDir, activationWidth,
        biasWidth, weightWidth, outputDir, logger, userDefinedArgs, quantOverridesPath
    ):
    generator = QOptionGenerator(
                    quantizationOptions, quantizationAlgorithms, modelFile, inputList, sdkDir, Constants.QNN,
                    activationWidth, biasWidth, weightWidth, outputDir, quantOverridesPath, userDefinedArgs, logger
                )
    result, quantizationVariationsWithCommand = generator.generate()
    return result, quantizationVariationsWithCommand

if __name__ == '__main__':
    main()
