#!/usr/bin/env python
#=============================================================================
#
#  Copyright (c) 2021-2022 Qualcomm Technologies, Inc.
#  All Rights Reserved.
#  Confidential and Proprietary - Qualcomm Technologies, Inc.
#
#=============================================================================
import os
import sys

sys.path.insert(0, os.path.abspath(os.path.join(sys.path[0], '../python/')))
import re
import json
import tarfile
from collections import OrderedDict
from pathlib import Path

import numpy as np
from qti.aisw.quantization_checker.QOptionGenerator import QOptionGenerator
from qti.aisw.quantization_checker.QOptionRunner import QOptionRunner
from qti.aisw.quantization_checker.utils import utils
from qti.aisw.quantization_checker.utils.ConfigParser import *
from qti.aisw.quantization_checker.utils.DataFormatter import DataFormatter
from qti.aisw.quantization_checker.utils.HistogramVisualizer import (
    HistogramGeneration, visualizeBiasTensors,
    visualizePerChannelWeightTensors, visualizeWeightTensors)
from qti.aisw.quantization_checker.utils.Logger import PrintOptions, getLogger
from qti.aisw.quantization_checker.utils.Op import Op
from qti.aisw.quantization_checker.utils.Processor import Processor
from qti.aisw.quantization_checker.utils.Progress import (Progress,
                                                          ProgressStage)


def main():
    # TODO: store as an editable JSON database of options
    quantizationVariations = [
                                'unquantized',
                                'enhanced', 'enhanced_cle',
                                'enhanced_pcq', 'enhanced_cle_pcq',
                                'tf', 'tf_cle',
                                'tf_pcq', 'tf_cle_pcq',
                                'adjusted', 'adjusted_cle',
                                'adjusted_pcq', 'adjusted_cle_pcq',
                                'symmetric', 'symmetric_cle',
                                'symmetric_pcq', 'symmetric_cle_pcq'
                             ]
    args = utils.getArguments()
    model = None
    caffeBin = None
    inputList = None
    sdkDir = None
    activationWidth = None
    outputDir = None
    generateHist = HistogramGeneration.SKIP_GENERATION
    biasWidth = None
    outputCsv = None
    quantOverridesPath = None

    configParams = extractConfigParams(args.config_file)
    comparisonAlgorithms = setDefaultAlgorithms()

    if configParams is not None:
        if "model" in configParams:
            model = configParams["model"]
        if "caffe_bin" in configParams:
            caffeBin = configParams["caffe_bin"]
        if "input_list" in configParams:
            inputList = configParams["input_list"]
        if "activation_width" in configParams:
            activationWidth = configParams["activation_width"]
        if "bias_width" in configParams:
            biasWidth = configParams["bias_width"]
        if "output_dir" in configParams:
            outputDir = configParams["output_dir"]
        if "weight_comparison_algorithms" in configParams:
            comparisonAlgorithms["weight_comparison_algorithms"] = configParams["weight_comparison_algorithms"]
        if "bias_comparison_algorithms" in configParams:
            comparisonAlgorithms["bias_comparison_algorithms"] = configParams["bias_comparison_algorithms"]
        if "act_comparison_algorithms" in configParams:
            comparisonAlgorithms["act_comparison_algorithms"] = configParams["act_comparison_algorithms"]
        if "input_data_analysis_algorithms" in configParams:
            comparisonAlgorithms["input_data_analysis_algorithms"] = configParams["input_data_analysis_algorithms"]
        if "output_csv" in configParams:
            outputCsv = configParams["output_csv"]
        if "generate_histogram" in configParams and configParams["generate_histogram"] == True:
            generateHist = HistogramGeneration.GENERATE_HISTOGRAM
        if "per_channel_histogram" in configParams and configParams["per_channel_histogram"] == True:
            generateHist = HistogramGeneration.GENERATE_PER_CHANNEL_HISTOGRAM
        if "quantization_overrides" in configParams and os.path.exists(configParams["quantization_overrides"]) == True:
            quantOverridesPath = configParams["quantization_overrides"]
    if args.model:
        model = args.model
    if args.caffe_bin:
        caffeBin = args.caffe_bin
    if args.input_list:
        inputList = args.input_list
    if args.activation_width:
        activationWidth = args.activation_width
    if args.bias_width:
        biasWidth = args.bias_width
    if args.output_dir:
        outputDir = args.output_dir
    if args.generate_histogram:
        generateHist = HistogramGeneration.GENERATE_HISTOGRAM
    if args.per_channel_histogram:
        generateHist = HistogramGeneration.GENERATE_PER_CHANNEL_HISTOGRAM
    if args.output_csv:
        outputCsv = args.output_csv
    skipBuild = args.skip_building_model
    skipGenerator = args.skip_generator
    skipRunner = args.skip_runner
    sdkDir = retrieveQnnSdkDir(os.path.abspath(__file__))
    if activationWidth is not None:
        Op.setActivationWidth(activationWidth)
    if biasWidth is not None:
        Op.setBiasWidth(biasWidth)
    if outputDir is None:
        print("ERROR! Output directory has not been specified, tool will now exit...")
        exit(-1)
    if model is None:
        print("ERROR! Input model file or directory of models has not been specified, tool will now exit...")
        exit(-1)

    logger = getLogger(outputDir, model, "qnn-quantization-checker-log")

    if sdkDir is None or not os.path.exists(sdkDir):
        logger.print("ERROR! Path to QNN SDK doesn't exist, please check the file path!")
        exit(-1)

    Progress.setProgressInfo(model, logger, skipGenerator, skipBuild, skipRunner)
    if os.path.isdir(model):
        models = utils.buildModelDict(model)
        skipFirstModel = True
        for modelData in models.values():
            if not skipFirstModel:
                Progress.updateModelProgress()
            skipFirstModel = False
            Progress.updateProgressLimit()
            if '.prototxt' in modelData['modelFile']:
                caffeBin = modelData['caffeBin']
            outputDir = os.path.dirname(modelData['modelFile'])
            if not os.path.exists(outputDir):
                os.makedirs(outputDir)
            inputFileNames = getInputFiles(modelData['inputList'])
            result = doAnalysis(quantizationVariations, modelData['modelFile'], logger, caffeBin, modelData['inputList'], sdkDir, activationWidth, biasWidth, outputDir, skipBuild, skipGenerator, skipRunner, inputFileNames, comparisonAlgorithms, args.config_file, generateHist, outputCsv, quantOverridesPath)
        Progress.updateProgress(Progress.getRemainingProgress()) 
        Progress.finishProcessor()
        exit(result)
    elif os.path.isfile(model):
        Progress.updateProgressLimit()
        if inputList is None or not os.path.exists(inputList):
            logger.print("ERROR! List of input files doesn't exist, please check the file path!")
            exit(-1)
        inputFileNames = getInputFiles(inputList)
        result = doAnalysis(quantizationVariations, model, logger, caffeBin, inputList, sdkDir, activationWidth, biasWidth, outputDir, skipBuild, skipGenerator, skipRunner, inputFileNames, comparisonAlgorithms, args.config_file, generateHist, outputCsv, quantOverridesPath)

        Progress.updateProgress(Progress.getRemainingProgress())
        Progress.finishProcessor()
        exit(result)
    else:
        exit(-1)

def doAnalysis(quantizationVariations, model, logger, caffeBin, inputList, sdkDir, activationWidth, biasWidth, outputDir, skipBuild, skipGenerator, skipRunner, inputFileNames, comparisonAlgorithms, userDefinedArgs, generateHist, outputCsv, quantOverridesPath):
    result = 0
    if not skipGenerator:
        result = runGenerator(model, inputList, sdkDir, caffeBin, activationWidth, biasWidth, outputDir, logger, userDefinedArgs, quantOverridesPath)
    if result != -1:
        allOps = getAllOpsFromJson(outputDir, quantizationVariations)
        logger.print('Extracting weights and biases files from bin.', PrintOptions.CONSOLE_LOGFILE)
        extractWeightsAndBiasesFiles(quantizationVariations, outputDir)
        logger.print('Extracting weights values from raw files.', PrintOptions.CONSOLE_LOGFILE)
        extractWeights(quantizationVariations, outputDir, allOps, logger)
        logger.print('Extracting biases values from raw files.', PrintOptions.CONSOLE_LOGFILE)
        extractBiases(quantizationVariations, outputDir, allOps, biasWidth)

        processor = Processor(quantizationVariations, comparisonAlgorithms, logger)
        formatter = DataFormatter(outputDir, model, inputFileNames, quantizationVariations, logger)
        formatter.setInputResults(processor.processInputData(extractInputData(model, inputList, logger)))
        if not skipRunner:
            logger.print('Building and running model.', PrintOptions.CONSOLE_LOGFILE)
            result = runRunner(inputList, sdkDir, outputDir, skipBuild, logger, userDefinedArgs)
        if result != -1:
            logger.print('Extracting activations from raw files.', PrintOptions.CONSOLE_LOGFILE)
            extractActivations(quantizationVariations, outputDir, allOps, inputFileNames)
            formatter.setActivationsResults(processor.processActivationResults(allOps))

        formatter.setWeightResults(processor.processWeightResults(allOps))
        formatter.setBiasResults(processor.processBiasResults(allOps))
        logger.print('Printing results to log file.', PrintOptions.CONSOLE_LOGFILE)
        formatter.printLog()
        logger.print('Printing results to console file.', PrintOptions.CONSOLE_LOGFILE)
        formatter.printConsole()
        logger.print('Printing results to HTML files.', PrintOptions.CONSOLE_LOGFILE)
        formatter.printHtml()
        if outputCsv:
            logger.print('Printing results to CSV files.', PrintOptions.CONSOLE_LOGFILE)
            formatter.printCsv()
            
        weightsHistAnalysisDir = os.path.join(outputDir, 'hist_analysis_weights')
        if generateHist == HistogramGeneration.GENERATE_PER_CHANNEL_HISTOGRAM:
            weightsHistAnalysisDir = os.path.join(outputDir, 'hist_analysis_weights')
            visualizePerChannelWeightTensors(quantizationVariations, allOps, weightsHistAnalysisDir, logger)
            biasesHistAnalysisDir = os.path.join(outputDir, 'hist_analysis_biases')
            visualizeBiasTensors(quantizationVariations, allOps, biasesHistAnalysisDir, logger)
        elif generateHist == HistogramGeneration.GENERATE_HISTOGRAM:
            weightsHistAnalysisDir = os.path.join(outputDir, 'hist_analysis_weights')
            visualizeWeightTensors(quantizationVariations, allOps, weightsHistAnalysisDir, logger)
            biasesHistAnalysisDir = os.path.join(outputDir, 'hist_analysis_biases')
            visualizeBiasTensors(quantizationVariations, allOps, biasesHistAnalysisDir, logger)
        
    return result

def retrieveQnnSdkDir(filePath):
    return str(Path(filePath).parent.parent.parent.parent)


def setDefaultAlgorithms():
    comparisonAlgorithms = {}
    comparisonAlgorithms["input_data_analysis_algorithms"] = [{"algo_name":"stats", "threshold":"2"}]
    comparisonAlgorithms["weight_comparison_algorithms"] = [{"algo_name":"minmax", "threshold":"10"}, {"algo_name":"maxdiff", "threshold":"10"}, {"algo_name":"sqnr", "threshold":"26"}, {"algo_name":"stats", "threshold":"2"}, {"algo_name":"data_range_analyzer"}, {"algo_name":"data_distribution_analyzer", "threshold":"0.6"}]
    comparisonAlgorithms["bias_comparison_algorithms"] = [{"algo_name":"minmax", "threshold":"10"}, {"algo_name":"maxdiff", "threshold":"10"}, {"algo_name":"sqnr", "threshold":"26"}, {"algo_name":"stats", "threshold":"2"}, {"algo_name":"data_range_analyzer"}, {"algo_name":"data_distribution_analyzer", "threshold":"0.6"}]
    comparisonAlgorithms["act_comparison_algorithms"] = [{"algo_name":"minmax", "threshold":"10"}]
    return comparisonAlgorithms

def getInputFiles(inputList):
    with open(inputList) as file:
        inputFileNames = file.readlines()
        inputFileNames = [line.rstrip() for line in inputFileNames]
    return inputFileNames

def getAllOpsFromJson(outputDir, quantizationVariations):
    allOpsMap = {}
    for quantizationVariation in quantizationVariations:
        opsInfo = getOpsFromJsonForQuantizationVariation(outputDir, quantizationVariation)
        if opsInfo is not None:
            allOpsMap[quantizationVariation] = opsInfo
    return allOpsMap

def getOpsFromJsonForQuantizationVariation(outputDir, quantizationVariation):
    jsonFilePath = os.path.join(outputDir, quantizationVariation, quantizationVariation + '_net.json')
    if not os.path.exists(jsonFilePath):
        return
    with open(jsonFilePath) as f:
        modelMeta = json.load(f, object_pairs_hook=OrderedDict)
    return parseOpDataFromJsonMeta(modelMeta)

def parseOpDataFromJsonMeta(modelMeta):
    nodes = modelMeta['graph']['nodes']
    opMap = {}
    for node in nodes.keys():
        op = Op(node)
        activationNodeName = nodes[node]['output_names'][0]
        op.setActivationNodeName(activationNodeName)
        if nodes[node]['input_names']:
            inputNames = nodes[node]['input_names']
            if nodes[node]['type'] == 'LSTM': 
                itr = 0
                for inputName in inputNames:
                    if Op.isLSTMBias(itr):
                        op.setBiasName(inputName)
                    else:
                        op.setWeightName(inputName)
                    itr += 1
            elif nodes[node]['type'] in Op.getOpTypesWithWeightsBiases():
                op.setInputNodeName(inputNames[0])
                op.setWeightName(inputNames[1])
                op.setBiasName(inputNames[2])
        opMap[node] = op
    return opMap

def extractActivations(quantizationVariations, outputDir, allOps, inputFileNames):
    for quantizationVariation in quantizationVariations:
        # skip quantized models which are failed to get converted correctly
        if quantizationVariation not in allOps:
            continue
        with open(os.path.join(outputDir, quantizationVariation, quantizationVariation + '_net.json')) as f:
            modelMeta = json.load(f, object_pairs_hook=OrderedDict)
        for item in allOps[quantizationVariation].items():
            op = allOps[quantizationVariation][item[0]]
            activationNodeName = op.getActivationNodeName()
            if activationNodeName is None:
                continue
            if quantizationVariation == 'unquantized':
                activationPath = os.path.join(outputDir, 'output', 'unquantized')
                resultCount = 0
                with os.scandir(activationPath) as allResults:
                    activationList = []
                    for resultDir in allResults:
                        if resultDir.is_dir():
                            activationFile = os.path.join(activationPath, resultDir.name, activationNodeName + '.raw')
                            if os.path.exists(activationFile) and os.path.isfile(activationFile):
                                activationList.append((inputFileNames[resultCount], np.fromfile(activationFile, dtype='float32')))
                                resultCount += 1
                    op.setActivations(activationList)
            op.setActivationScale(modelMeta['graph']['tensors'][activationNodeName]['quant_params']['scale_offset']['scale'])
            op.setActivationOffset(modelMeta['graph']['tensors'][activationNodeName]['quant_params']['scale_offset']['offset'])
            if op.getInputNodeName() is not None:
                op.setInputNodeScale(modelMeta['graph']['tensors'][op.getInputNodeName()]['quant_params']['scale_offset']['scale'])
            allOps[quantizationVariation][item[0]] = op

def extractInputData(model, inputList, logger):
    inputDirPath = os.path.dirname(model)
    inputData = {}
    with open(inputList) as file:
        inputFileNames = file.readlines()
        for line in inputFileNames:
            filenames = line.rstrip()
            for file in filenames.split():
                if not os.path.exists(os.path.join(inputDirPath, file)):
                    logger.print('Following file - ' + file + ' from inputList is not accessible, trying to further extract input file names.', PrintOptions.CONSOLE_LOGFILE)
                    file = re.split('=|:', file)[-1]
                    if not os.path.exists(file):
                        logger.print('Following file - ' + file + ' from inputList is still not accessible, so tool is exiting.', PrintOptions.CONSOLE_LOGFILE)
                        logger.print("ERROR! List of input files doesn't exist , please check the file path!")
                        exit(-1)
                    else:
                        logger.print('Following file - ' + file + ' from inputList is now accessible, tool will progress further.', PrintOptions.CONSOLE_LOGFILE)
                inputData[file] = np.fromfile(os.path.join(inputDirPath, file), dtype='float32')
    return inputData

def extractWeights(quantizationVariations, outputDir, allOps, logger):
    for quantizationVariation in quantizationVariations:
        # skip quantized models which are failed to get converted correctly
        if quantizationVariation not in allOps:
            continue
        with open(os.path.join(outputDir, quantizationVariation, quantizationVariation + '_net.json')) as f:
            modelMeta = json.load(f, object_pairs_hook=OrderedDict)
        for item in allOps[quantizationVariation].items():
            op = allOps[quantizationVariation][item[0]]
            if op.getWeightName() not in (None, ''):
                weightName = op.getWeightName()
                dtype = None
                quantEncoding = modelMeta['graph']['tensors'][weightName]['quant_params']['encoding']
                op.setWeightsQuantEncoding(quantEncoding)
                if 'dims' in modelMeta['graph']['tensors'][weightName]:
                    op.setWeightsDims(modelMeta['graph']['tensors'][weightName]['dims'])
                elif 'current_dims' in modelMeta['graph']['tensors'][weightName]:
                    op.setWeightsDims(modelMeta['graph']['tensors'][weightName]['current_dims'])
                else:
                    logger.print('Extracting weight values failed due to keyError while retrieving weight dimension.')
                    exit(-1)
                # quantization encoding=0 for non-pcq weights
                if quantEncoding == 0:
                    op.setWeightsScaleOffset(modelMeta['graph']['tensors'][weightName]['quant_params']['scale_offset'])
                    dtype = 'uint8'
                # quantization encoding=1 for pcq weights
                elif quantEncoding == 1:
                    op.setWeightsScaleOffset(modelMeta['graph']['tensors'][weightName]['quant_params']['axis_scale_offset'])
                    dtype = 'int8'
                if quantizationVariation == 'unquantized':
                    op.setWeights(np.fromfile(os.path.join(outputDir, quantizationVariation, weightName + '.raw'), dtype='float32'))
                else:
                    op.setWeights(np.fromfile(os.path.join(outputDir, quantizationVariation, weightName + '.raw'), dtype=dtype))
            allOps[quantizationVariation][item[0]] = op

def extractBiases(quantizationVariations, outputDir, allOps, biasWidth):
    for quantizationVariation in quantizationVariations:
        # skip quantized models which are failed to get converted correctly
        if quantizationVariation not in allOps:
            continue
        with open(os.path.join(outputDir, quantizationVariation, quantizationVariation + '_net.json')) as f:
            modelMeta = json.load(f, object_pairs_hook=OrderedDict)
        for item in allOps[quantizationVariation].items():
            op = allOps[quantizationVariation][item[0]]
            if op.getBiasName() not in (None, ''):
                biasName = op.getBiasName()
                op.setBiasScale(modelMeta['graph']['tensors'][biasName]['quant_params']['scale_offset']['scale'])
                op.setBiasOffset(modelMeta['graph']['tensors'][biasName]['quant_params']['scale_offset']['offset'])
                dataType = modelMeta['graph']['tensors'][biasName]['data_type']
                # TODO: check if bias raw file exists and report if not...
                biasRawFilePath = os.path.join(outputDir, quantizationVariation, biasName + '.raw')
                if not os.path.exists(biasRawFilePath):
                    continue
                if quantizationVariation == 'unquantized':
                    op.setBiases(np.fromfile(biasRawFilePath, dtype='float32'))
                elif dataType == Op.getUint8QnnCode():
                    op.setBiases(np.fromfile(biasRawFilePath, dtype='uint8'))
                else:
                    op.setBiases(np.fromfile(biasRawFilePath, dtype='int32'))
            allOps[quantizationVariation][item[0]] = op

def extractWeightsAndBiasesFiles(quantizationVariations, outputDir):
    for quantizationVariation in quantizationVariations:
        fileToExtract = os.path.join(outputDir, quantizationVariation, quantizationVariation + '.bin')
        if not os.path.exists(fileToExtract):
            continue
        # untar the bin file
        binFile = tarfile.open(fileToExtract, 'r')
        extractDir = os.path.dirname(fileToExtract)
        binFile.extractall(extractDir)

def runRunner(inputList, sdkDir, outputDir, skipBuild, logger, userDefinedArgs):
    runner = QOptionRunner(outputDir, inputList, sdkDir, os.path.join(outputDir, 'output'), userDefinedArgs, logger, skipBuild)
    result = runner.run()
    Progress.updateProgress(Progress.getStepSize(ProgressStage.RUNNER))
    return result

def runGenerator(modelFile, inputList, sdkDir, caffeBin, activationWidth, biasWidth, outputDir, logger, userDefinedArgs, quantOverridesPath):
    generator = QOptionGenerator(modelFile, caffeBin, inputList, sdkDir, activationWidth, biasWidth, outputDir, quantOverridesPath, userDefinedArgs, logger)
    result = generator.generate()
    return result

if __name__ == '__main__':
    main()
